"""
ì£¼ì‹ ì°¨íŠ¸ íŒ¨í„´ ê¸°ë°˜ CNN ëª¨ë¸
- ì°¨íŠ¸ ì´ë¯¸ì§€ë¥¼ í•™ìŠµí•˜ì—¬ ë‹¤ìŒë‚  ìƒìŠ¹/í•˜ë½ ì˜ˆì¸¡
- Dataset: dataset-2021/up, dataset-2021/down
"""

import os
import sys
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, models
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import warnings
warnings.filterwarnings('ignore')

# Windows ì½˜ì†” ì¸ì½”ë”© ì„¤ì •
if sys.platform == 'win32':
    import codecs
    sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer, 'ignore')
    sys.stderr = codecs.getwriter('utf-8')(sys.stderr.buffer, 'ignore')

# ëœë¤ ì‹œë“œ ê³ ì •
np.random.seed(42)
tf.random.set_seed(42)

class StockChartCNN:
    """ì£¼ì‹ ì°¨íŠ¸ CNN ëª¨ë¸ í´ë˜ìŠ¤"""
    
    def __init__(self, data_dir='dataset-2021', img_size=(100, 100), batch_size=32):
        """
        Args:
            data_dir: ë°ì´í„°ì…‹ ë””ë ‰í† ë¦¬
            img_size: ì´ë¯¸ì§€ í¬ê¸° (width, height)
            batch_size: ë°°ì¹˜ í¬ê¸°
        """
        self.data_dir = data_dir
        self.img_size = img_size
        self.batch_size = batch_size
        self.model = None
        self.history = None
        
    def explore_data(self):
        """ë°ì´í„°ì…‹ íƒìƒ‰"""
        print("=" * 60)
        print("ğŸ“Š ë°ì´í„°ì…‹ íƒìƒ‰")
        print("=" * 60)
        
        up_dir = os.path.join(self.data_dir, 'up')
        down_dir = os.path.join(self.data_dir, 'down')
        
        up_files = os.listdir(up_dir)
        down_files = os.listdir(down_dir)
        
        print(f"âœ… ìƒìŠ¹(Up) ì´ë¯¸ì§€: {len(up_files):,}ê°œ")
        print(f"âŒ í•˜ë½(Down) ì´ë¯¸ì§€: {len(down_files):,}ê°œ")
        print(f"ğŸ“ˆ ì´ ì´ë¯¸ì§€: {len(up_files) + len(down_files):,}ê°œ")
        print(f"âš–ï¸  í´ë˜ìŠ¤ ë¹„ìœ¨: Up={len(up_files)/(len(up_files)+len(down_files))*100:.1f}%, "
              f"Down={len(down_files)/(len(up_files)+len(down_files))*100:.1f}%")
        
        # ìƒ˜í”Œ ì´ë¯¸ì§€ í¬ê¸° í™•ì¸
        sample_img_path = os.path.join(up_dir, up_files[0])
        sample_img = Image.open(sample_img_path)
        print(f"ğŸ“ ìƒ˜í”Œ ì´ë¯¸ì§€ í¬ê¸°: {sample_img.size}")
        print(f"ğŸ¨ ì´ë¯¸ì§€ ëª¨ë“œ: {sample_img.mode}")
        print("=" * 60)
        
        return len(up_files), len(down_files)
    
    def create_data_generators(self, validation_split=0.2):
        """ë°ì´í„° ì œë„ˆë ˆì´í„° ìƒì„± (Data Augmentation í¬í•¨)"""
        print("\nğŸ”„ ë°ì´í„° ì œë„ˆë ˆì´í„° ìƒì„± ì¤‘...")
        
        # Training ë°ì´í„° ì¦ê°•
        train_datagen = ImageDataGenerator(
            rescale=1./255,
            validation_split=validation_split,
            rotation_range=10,
            width_shift_range=0.1,
            height_shift_range=0.1,
            horizontal_flip=True,
            zoom_range=0.1,
            fill_mode='nearest'
        )
        
        # Validation ë°ì´í„° (ì¦ê°• ì—†ìŒ)
        val_datagen = ImageDataGenerator(
            rescale=1./255,
            validation_split=validation_split
        )
        
        # Training ì œë„ˆë ˆì´í„°
        self.train_generator = train_datagen.flow_from_directory(
            self.data_dir,
            target_size=self.img_size,
            batch_size=self.batch_size,
            class_mode='binary',
            subset='training',
            shuffle=True,
            seed=42
        )
        
        # Validation ì œë„ˆë ˆì´í„°
        self.val_generator = val_datagen.flow_from_directory(
            self.data_dir,
            target_size=self.img_size,
            batch_size=self.batch_size,
            class_mode='binary',
            subset='validation',
            shuffle=False,
            seed=42
        )
        
        print(f"âœ… Training ìƒ˜í”Œ: {self.train_generator.samples:,}ê°œ")
        print(f"âœ… Validation ìƒ˜í”Œ: {self.val_generator.samples:,}ê°œ")
        print(f"ğŸ“‹ í´ë˜ìŠ¤ ë§¤í•‘: {self.train_generator.class_indices}")
        
        return self.train_generator, self.val_generator
    
    def build_model(self):
        """CNN ëª¨ë¸ êµ¬ì¶•"""
        print("\nğŸ—ï¸  CNN ëª¨ë¸ êµ¬ì¶• ì¤‘...")
        
        model = models.Sequential([
            # ì²« ë²ˆì§¸ Conv Block
            layers.Conv2D(32, (3, 3), activation='relu', padding='same', 
                         input_shape=(self.img_size[0], self.img_size[1], 3)),
            layers.Conv2D(32, (3, 3), activation='relu', padding='same'),
            layers.BatchNormalization(),
            layers.MaxPooling2D((2, 2)),
            layers.Dropout(0.25),
            
            # ë‘ ë²ˆì§¸ Conv Block
            layers.Conv2D(64, (3, 3), activation='relu', padding='same'),
            layers.Conv2D(64, (3, 3), activation='relu', padding='same'),
            layers.BatchNormalization(),
            layers.MaxPooling2D((2, 2)),
            layers.Dropout(0.25),
            
            # ì„¸ ë²ˆì§¸ Conv Block
            layers.Conv2D(128, (3, 3), activation='relu', padding='same'),
            layers.Conv2D(128, (3, 3), activation='relu', padding='same'),
            layers.BatchNormalization(),
            layers.MaxPooling2D((2, 2)),
            layers.Dropout(0.25),
            
            # ë„¤ ë²ˆì§¸ Conv Block
            layers.Conv2D(256, (3, 3), activation='relu', padding='same'),
            layers.Conv2D(256, (3, 3), activation='relu', padding='same'),
            layers.BatchNormalization(),
            layers.MaxPooling2D((2, 2)),
            layers.Dropout(0.25),
            
            # Fully Connected Layers
            layers.Flatten(),
            layers.Dense(512, activation='relu'),
            layers.BatchNormalization(),
            layers.Dropout(0.5),
            layers.Dense(256, activation='relu'),
            layers.BatchNormalization(),
            layers.Dropout(0.5),
            
            # Output Layer
            layers.Dense(1, activation='sigmoid')
        ])
        
        # ëª¨ë¸ ì»´íŒŒì¼
        model.compile(
            optimizer=keras.optimizers.Adam(learning_rate=0.001),
            loss='binary_crossentropy',
            metrics=['accuracy', 
                    keras.metrics.Precision(name='precision'),
                    keras.metrics.Recall(name='recall'),
                    keras.metrics.AUC(name='auc')]
        )
        
        self.model = model
        
        print("âœ… ëª¨ë¸ êµ¬ì¶• ì™„ë£Œ")
        print(f"ğŸ“Š ì´ íŒŒë¼ë¯¸í„°: {model.count_params():,}ê°œ")
        
        return model
    
    def train(self, epochs=50, save_path='models/best_model.h5'):
        """ëª¨ë¸ í•™ìŠµ"""
        print("\nğŸš€ ëª¨ë¸ í•™ìŠµ ì‹œì‘")
        print("=" * 60)
        
        # ì „ì²´ ë°ì´í„°ì…‹ í¬ê¸° ê³„ì‚°
        total_samples = self.train_generator.samples + self.val_generator.samples
        print(f"ğŸ“Š ì „ì²´ ë°ì´í„°ì…‹: {total_samples:,}ê°œ")
        print(f"   - Training: {self.train_generator.samples:,}ê°œ")
        print(f"   - Validation: {self.val_generator.samples:,}ê°œ")
        print(f"   - ì˜ˆìƒ í•™ìŠµ ì‹œê°„: {epochs} ì—í¬í¬")
        print("=" * 60)
        
        # ì½œë°± ì„¤ì •
        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        
        # ì§„í–‰ë¥  í‘œì‹œë¥¼ ìœ„í•œ ì»¤ìŠ¤í…€ ì½œë°±
        class ProgressCallback(keras.callbacks.Callback):
            def __init__(self, total_epochs, total_samples):
                self.total_epochs = total_epochs
                self.total_samples = total_samples
                self.current_epoch = 0
                
            def on_epoch_begin(self, epoch, logs=None):
                self.current_epoch = epoch + 1
                progress = (self.current_epoch / self.total_epochs) * 100
                
                print(f"\nğŸ“ˆ Epoch {self.current_epoch}/{self.total_epochs} ì‹œì‘")
                print(f"   ì§„í–‰ë¥ : {progress:.1f}% ({self.current_epoch}/{self.total_epochs})")
                
                # 25% ë‹¨ìœ„ë¡œ í‘œì‹œ
                if progress >= 25 and progress < 50:
                    print("   ğŸŸ¡ 25% ì™„ë£Œ - í•™ìŠµì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤...")
                elif progress >= 50 and progress < 75:
                    print("   ğŸŸ  50% ì™„ë£Œ - ì ˆë°˜ì„ ë„˜ì—ˆìŠµë‹ˆë‹¤!")
                elif progress >= 75 and progress < 100:
                    print("   ğŸ”´ 75% ì™„ë£Œ - ê±°ì˜ ë‹¤ ì™”ìŠµë‹ˆë‹¤!")
                elif progress >= 100:
                    print("   ğŸ‰ 100% ì™„ë£Œ!")
                
            def on_epoch_end(self, epoch, logs=None):
                if logs:
                    train_acc = logs.get('accuracy', 0)
                    val_acc = logs.get('val_accuracy', 0)
                    train_loss = logs.get('loss', 0)
                    val_loss = logs.get('val_loss', 0)
                    
                    print(f"   ğŸ“Š ê²°ê³¼:")
                    print(f"      Training - Loss: {train_loss:.4f}, Accuracy: {train_acc:.4f}")
                    print(f"      Validation - Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}")
                    
                    # ì„±ëŠ¥ ê°œì„  í‘œì‹œ
                    if epoch > 0:
                        prev_val_acc = getattr(self, 'prev_val_acc', 0)
                        if val_acc > prev_val_acc:
                            print(f"      ğŸ“ˆ ì„±ëŠ¥ ê°œì„ ! (+{val_acc - prev_val_acc:.4f})")
                        elif val_acc < prev_acc:
                            print(f"      ğŸ“‰ ì„±ëŠ¥ í•˜ë½ (-{prev_val_acc - val_acc:.4f})")
                    
                    self.prev_val_acc = val_acc
                
                print("   " + "-" * 50)
        
        callbacks = [
            ProgressCallback(epochs, total_samples),
            EarlyStopping(
                monitor='val_loss',
                patience=15,  # ë” ê¸´ patience
                restore_best_weights=True,
                verbose=1
            ),
            ModelCheckpoint(
                save_path,
                monitor='val_accuracy',
                save_best_only=True,
                verbose=1
            ),
            ReduceLROnPlateau(
                monitor='val_loss',
                factor=0.5,
                patience=7,  # ë” ê¸´ patience
                min_lr=1e-7,
                verbose=1
            )
        ]
        
        print(f"\nâ° í•™ìŠµ ì‹œì‘ ì‹œê°„: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("ğŸ’¡ ì¤‘ê°„ì— ì¤‘ë‹¨í•˜ë ¤ë©´ Ctrl+Cë¥¼ ëˆ„ë¥´ì„¸ìš”")
        print("=" * 60)
        
        # í•™ìŠµ
        try:
            self.history = self.model.fit(
                self.train_generator,
                epochs=epochs,
                validation_data=self.val_generator,
                callbacks=callbacks,
                verbose=0  # ì»¤ìŠ¤í…€ ì½œë°±ì—ì„œ ì¶œë ¥
            )
            
            print("\n" + "=" * 60)
            print("âœ… í•™ìŠµ ì™„ë£Œ!")
            print(f"â° ì™„ë£Œ ì‹œê°„: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}")
            print("=" * 60)
            
        except KeyboardInterrupt:
            print("\n\nâš ï¸ ì‚¬ìš©ìì— ì˜í•´ í•™ìŠµì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
            print("ğŸ’¾ í˜„ì¬ê¹Œì§€ì˜ ëª¨ë¸ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            return self.history
        
        return self.history
    
    def evaluate(self):
        """ëª¨ë¸ í‰ê°€"""
        print("\nğŸ“Š ëª¨ë¸ í‰ê°€")
        print("=" * 60)
        
        # Validation ë°ì´í„°ë¡œ ì˜ˆì¸¡
        val_steps = len(self.val_generator)
        y_pred_proba = self.model.predict(self.val_generator, steps=val_steps)
        y_pred = (y_pred_proba > 0.5).astype(int).flatten()
        y_true = self.val_generator.classes
        
        # í‰ê°€ ì§€í‘œ ê³„ì‚°
        accuracy = accuracy_score(y_true, y_pred)
        print(f"\nâœ… Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)")
        
        print("\nğŸ“‹ Classification Report:")
        print(classification_report(y_true, y_pred, 
                                   target_names=['Down (0)', 'Up (1)']))
        
        # Confusion Matrix
        cm = confusion_matrix(y_true, y_pred)
        
        return accuracy, cm, y_true, y_pred
    
    def plot_training_history(self, save_path='results/training_history.png'):
        """í•™ìŠµ ê³¼ì • ì‹œê°í™”"""
        print("\nğŸ“ˆ í•™ìŠµ ê³¼ì • ì‹œê°í™” ì¤‘...")
        
        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        
        # Accuracy
        axes[0, 0].plot(self.history.history['accuracy'], label='Train Accuracy')
        axes[0, 0].plot(self.history.history['val_accuracy'], label='Val Accuracy')
        axes[0, 0].set_title('Model Accuracy', fontsize=14, fontweight='bold')
        axes[0, 0].set_xlabel('Epoch')
        axes[0, 0].set_ylabel('Accuracy')
        axes[0, 0].legend()
        axes[0, 0].grid(True, alpha=0.3)
        
        # Loss
        axes[0, 1].plot(self.history.history['loss'], label='Train Loss')
        axes[0, 1].plot(self.history.history['val_loss'], label='Val Loss')
        axes[0, 1].set_title('Model Loss', fontsize=14, fontweight='bold')
        axes[0, 1].set_xlabel('Epoch')
        axes[0, 1].set_ylabel('Loss')
        axes[0, 1].legend()
        axes[0, 1].grid(True, alpha=0.3)
        
        # Precision
        axes[1, 0].plot(self.history.history['precision'], label='Train Precision')
        axes[1, 0].plot(self.history.history['val_precision'], label='Val Precision')
        axes[1, 0].set_title('Model Precision', fontsize=14, fontweight='bold')
        axes[1, 0].set_xlabel('Epoch')
        axes[1, 0].set_ylabel('Precision')
        axes[1, 0].legend()
        axes[1, 0].grid(True, alpha=0.3)
        
        # Recall
        axes[1, 1].plot(self.history.history['recall'], label='Train Recall')
        axes[1, 1].plot(self.history.history['val_recall'], label='Val Recall')
        axes[1, 1].set_title('Model Recall', fontsize=14, fontweight='bold')
        axes[1, 1].set_xlabel('Epoch')
        axes[1, 1].set_ylabel('Recall')
        axes[1, 1].legend()
        axes[1, 1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"âœ… ì €ì¥ ì™„ë£Œ: {save_path}")
        plt.close()
    
    def plot_confusion_matrix(self, cm, save_path='results/confusion_matrix.png'):
        """Confusion Matrix ì‹œê°í™”"""
        print("\nğŸ“Š Confusion Matrix ì‹œê°í™” ì¤‘...")
        
        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        
        plt.figure(figsize=(10, 8))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=True,
                   xticklabels=['Down (0)', 'Up (1)'],
                   yticklabels=['Down (0)', 'Up (1)'],
                   annot_kws={'size': 16})
        plt.title('Confusion Matrix', fontsize=16, fontweight='bold', pad=20)
        plt.ylabel('True Label', fontsize=12)
        plt.xlabel('Predicted Label', fontsize=12)
        
        # ì •í™•ë„ í‘œì‹œ
        accuracy = (cm[0, 0] + cm[1, 1]) / cm.sum()
        plt.text(1, -0.3, f'Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)',
                ha='center', fontsize=14, fontweight='bold')
        
        plt.tight_layout()
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"âœ… ì €ì¥ ì™„ë£Œ: {save_path}")
        plt.close()
    
    def predict_image(self, image_path):
        """ë‹¨ì¼ ì´ë¯¸ì§€ ì˜ˆì¸¡"""
        # ì´ë¯¸ì§€ ë¡œë“œ ë° ì „ì²˜ë¦¬
        img = Image.open(image_path)
        img = img.resize(self.img_size)
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        # ì˜ˆì¸¡
        prediction = self.model.predict(img_array, verbose=0)[0][0]
        
        result = {
            'prediction': 'Up (ìƒìŠ¹)' if prediction > 0.5 else 'Down (í•˜ë½)',
            'probability': prediction if prediction > 0.5 else 1 - prediction,
            'up_prob': prediction,
            'down_prob': 1 - prediction
        }
        
        return result
    
    def save_model_summary(self, save_path='results/model_summary.txt'):
        """ëª¨ë¸ êµ¬ì¡° ì €ì¥"""
        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        
        with open(save_path, 'w', encoding='utf-8') as f:
            self.model.summary(print_fn=lambda x: f.write(x + '\n'))
        
        print(f"âœ… ëª¨ë¸ êµ¬ì¡° ì €ì¥: {save_path}")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("\n" + "=" * 60)
    print("ğŸš€ ì£¼ì‹ ì°¨íŠ¸ íŒ¨í„´ ê¸°ë°˜ CNN ëª¨ë¸ í”„ë¡œì íŠ¸")
    print("ğŸ”¥ ì „ì²´ ë°ì´í„°ì…‹ í•™ìŠµ ëª¨ë“œ (1,015,729ê°œ ì´ë¯¸ì§€)")
    print("=" * 60)
    
    # 1. ëª¨ë¸ ê°ì²´ ìƒì„± (ë” í° ë°°ì¹˜ í¬ê¸°ë¡œ íš¨ìœ¨ì„± í–¥ìƒ)
    stock_cnn = StockChartCNN(
        data_dir='dataset-2021',
        img_size=(100, 100),
        batch_size=128  # ë°°ì¹˜ í¬ê¸° ì¦ê°€
    )
    
    # 2. ë°ì´í„° íƒìƒ‰
    stock_cnn.explore_data()
    
    # 3. ë°ì´í„° ì œë„ˆë ˆì´í„° ìƒì„±
    stock_cnn.create_data_generators(validation_split=0.2)
    
    # 4. ëª¨ë¸ êµ¬ì¶•
    stock_cnn.build_model()
    stock_cnn.model.summary()
    
    # 5. ëª¨ë¸ êµ¬ì¡° ì €ì¥
    stock_cnn.save_model_summary()
    
    # 6. í•™ìŠµ ì‹œì‘ ì „ í™•ì¸
    print("\n" + "=" * 60)
    print("âš ï¸  ì „ì²´ ë°ì´í„°ì…‹ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤!")
    print("=" * 60)
    print(f"ğŸ“Š ë°ì´í„°ì…‹ í¬ê¸°: {stock_cnn.train_generator.samples + stock_cnn.val_generator.samples:,}ê°œ")
    print(f"â±ï¸  ì˜ˆìƒ ì†Œìš” ì‹œê°„: 10-20ì‹œê°„ (GPU) / 100+ì‹œê°„ (CPU)")
    print(f"ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: ì•½ 8-16GB RAM")
    print(f"ğŸ–¥ï¸  GPU ê¶Œì¥: NVIDIA GPU (CUDA)")
    print("=" * 60)
    
    confirm = input("\nê³„ì† ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ")
    if confirm.lower() != 'y':
        print("âŒ í•™ìŠµì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        return
    
    # 7. ëª¨ë¸ í•™ìŠµ (ë” ë§ì€ ì—í¬í¬)
    print("\nğŸš€ í•™ìŠµ ì‹œì‘!")
    stock_cnn.train(epochs=100, save_path='models/best_stock_chart_model.h5')
    
    # 8. ëª¨ë¸ í‰ê°€
    accuracy, cm, y_true, y_pred = stock_cnn.evaluate()
    
    # 9. ê²°ê³¼ ì‹œê°í™”
    stock_cnn.plot_training_history()
    stock_cnn.plot_confusion_matrix(cm)
    
    # 10. ìƒ˜í”Œ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸
    print("\n" + "=" * 60)
    print("ğŸ”® ìƒ˜í”Œ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    # Up ìƒ˜í”Œ
    up_sample = os.path.join('dataset-2021/up', os.listdir('dataset-2021/up')[0])
    result = stock_cnn.predict_image(up_sample)
    print(f"\nğŸ“ˆ Up ìƒ˜í”Œ ì˜ˆì¸¡:")
    print(f"   íŒŒì¼: {os.path.basename(up_sample)}")
    print(f"   ì˜ˆì¸¡: {result['prediction']}")
    print(f"   í™•ë¥ : {result['probability']:.2%}")
    print(f"   Up í™•ë¥ : {result['up_prob']:.2%}, Down í™•ë¥ : {result['down_prob']:.2%}")
    
    # Down ìƒ˜í”Œ
    down_sample = os.path.join('dataset-2021/down', os.listdir('dataset-2021/down')[0])
    result = stock_cnn.predict_image(down_sample)
    print(f"\nğŸ“‰ Down ìƒ˜í”Œ ì˜ˆì¸¡:")
    print(f"   íŒŒì¼: {os.path.basename(down_sample)}")
    print(f"   ì˜ˆì¸¡: {result['prediction']}")
    print(f"   í™•ë¥ : {result['probability']:.2%}")
    print(f"   Up í™•ë¥ : {result['up_prob']:.2%}, Down í™•ë¥ : {result['down_prob']:.2%}")
    
    print("\n" + "=" * 60)
    print("ğŸ‰ ì „ì²´ í•™ìŠµ ì™„ë£Œ!")
    print(f"ğŸ“Š ìµœì¢… ì •í™•ë„: {accuracy:.4f} ({accuracy*100:.2f}%)")
    print("=" * 60)


if __name__ == '__main__':
    main()
