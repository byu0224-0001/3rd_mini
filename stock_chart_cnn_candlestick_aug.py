"""
ì£¼ì‹ ì°¨íŠ¸ íŒ¨í„´ ê¸°ë°˜ CNN ëª¨ë¸ - ìº”ë“¤ìŠ¤í‹± íŠ¹í™” ë°ì´í„° ì¦ê°• ë²„ì „
- ë…¼ë¬¸ ê¸°ë°˜ ìº”ë“¤ìŠ¤í‹± ì°¨íŠ¸ ì „ìš© ë°ì´í„° ì¦ê°•
- ìº”ë“¤ ë¬´ì‘ìœ„ ì´ë™ (100%, 50%, 10%)
- ìº”ë“¤ ì´ë™ í¬ê¸° (0.003, 0.002, 0.001, 0.00025)
- ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ ì¶”ê°€ (í‰ê·  0, ë¶„ì‚° 0.01)
- ResNet50 Transfer Learning + Fine-tuning
"""

import os
import sys
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image
import shutil
import random
from pathlib import Path
from sklearn.metrics import (classification_report, confusion_matrix, accuracy_score,
                             roc_auc_score, roc_curve, f1_score, precision_recall_curve)
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, models
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import warnings
warnings.filterwarnings('ignore')

# Windows ì½˜ì†” ì¸ì½”ë”© ì„¤ì •
if sys.platform == 'win32':
    import codecs
    sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer, 'ignore')
    sys.stderr = codecs.getwriter('utf-8')(sys.stderr.buffer, 'ignore')

# GPU ì„¤ì •
print("ğŸ”§ GPU/CUDA ì„¤ì • ì¤‘...")
print(f"TensorFlow ë²„ì „: {tf.__version__}")

try:
    gpus = tf.config.experimental.list_physical_devices('GPU')
    print(f"ğŸ” ê°ì§€ëœ GPU: {len(gpus)}ê°œ")
    
    if gpus:
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
        print(f"âœ… GPU ì‚¬ìš©: {len(gpus)}ê°œ")
    else:
        print("âš ï¸ GPUë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPUë¡œ í•™ìŠµí•©ë‹ˆë‹¤.")
        tf.config.threading.set_inter_op_parallelism_threads(0)
        tf.config.threading.set_intra_op_parallelism_threads(0)
except Exception as e:
    print(f"âš ï¸ GPU ì„¤ì • ì˜¤ë¥˜: {e}")

np.random.seed(42)
tf.random.set_seed(42)


class CandlestickAugmentation:
    """ìº”ë“¤ìŠ¤í‹± ì°¨íŠ¸ ì „ìš© ë°ì´í„° ì¦ê°•"""
    
    @staticmethod
    def add_gaussian_noise(image, mean=0, var=0.01):
        """
        ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ ì¶”ê°€
        Args:
            image: ì…ë ¥ ì´ë¯¸ì§€ (numpy array, 0-1 ë²”ìœ„)
            mean: ë…¸ì´ì¦ˆ í‰ê· 
            var: ë…¸ì´ì¦ˆ ë¶„ì‚°
        """
        sigma = var ** 0.5
        gaussian = np.random.normal(mean, sigma, image.shape)
        noisy_image = image + gaussian
        return np.clip(noisy_image, 0, 1)
    
    @staticmethod
    def shift_candles_vertically(image, shift_ratio=0.5, shift_amount=0.003):
        """
        ìº”ë“¤ìŠ¤í‹±ì„ ìˆ˜ì§ìœ¼ë¡œ ë¬´ì‘ìœ„ ì´ë™
        Args:
            image: ì…ë ¥ ì´ë¯¸ì§€ (numpy array, 0-1 ë²”ìœ„)
            shift_ratio: ì´ë™í•  ìº”ë“¤ ë¹„ìœ¨ (1.0=100%, 0.5=50%, 0.1=10%)
            shift_amount: ì´ë™ í¬ê¸° (0.003, 0.002, 0.001, 0.00025)
        """
        # ì´ë¯¸ì§€ ë³µì‚¬
        shifted_image = image.copy()
        
        # ì´ë¯¸ì§€ ë†’ì´
        height = image.shape[0]
        
        # í”½ì…€ ë‹¨ìœ„ë¡œ ì´ë™ëŸ‰ ê³„ì‚°
        pixel_shift = int(height * shift_amount)
        
        if pixel_shift > 0:
            # ìƒí•˜ ëœë¤ ì´ë™
            direction = np.random.choice([-1, 1])
            shift_pixels = direction * pixel_shift
            
            # ì´ë¯¸ì§€ë¥¼ ìˆ˜ì§ìœ¼ë¡œ ì´ë™
            if shift_pixels > 0:
                shifted_image[shift_pixels:, :] = image[:-shift_pixels, :]
                shifted_image[:shift_pixels, :] = 0
            elif shift_pixels < 0:
                shifted_image[:shift_pixels, :] = image[-shift_pixels:, :]
                shifted_image[shift_pixels:, :] = 0
        
        return shifted_image


class CandlestickDataGenerator(keras.utils.Sequence):
    """ìº”ë“¤ìŠ¤í‹± ì°¨íŠ¸ ì „ìš© ë°ì´í„° ì œë„ˆë ˆì´í„°"""
    
    def __init__(self, directory, class_mode='binary', batch_size=32, 
                 img_size=(128, 128), shuffle=True, augment=True, seed=42):
        self.directory = directory
        self.class_mode = class_mode
        self.batch_size = batch_size
        self.img_size = img_size
        self.shuffle = shuffle
        self.augment = augment
        self.seed = seed
        
        # í´ë˜ìŠ¤ ë° íŒŒì¼ ë¡œë“œ
        self.classes = ['down', 'up']
        self.class_indices = {name: idx for idx, name in enumerate(self.classes)}
        
        self.image_paths = []
        self.labels = []
        
        for class_name in self.classes:
            class_dir = os.path.join(directory, class_name)
            if os.path.exists(class_dir):
                files = [f for f in os.listdir(class_dir) 
                        if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
                
                for f in files:
                    self.image_paths.append(os.path.join(class_dir, f))
                    self.labels.append(self.class_indices[class_name])
        
        self.samples = len(self.image_paths)
        self.indexes = np.arange(self.samples)
        
        if self.shuffle:
            np.random.seed(self.seed)
            np.random.shuffle(self.indexes)
        
        # ì¦ê°• ì„¤ì •
        self.aug_configs = [
            {'shift_ratio': 1.0, 'shift_amount': 0.003},   # 100% ìº”ë“¤, 0.003 ì´ë™
            {'shift_ratio': 1.0, 'shift_amount': 0.002},   # 100% ìº”ë“¤, 0.002 ì´ë™
            {'shift_ratio': 0.5, 'shift_amount': 0.003},   # 50% ìº”ë“¤, 0.003 ì´ë™
            {'shift_ratio': 0.5, 'shift_amount': 0.001},   # 50% ìº”ë“¤, 0.001 ì´ë™
            {'shift_ratio': 0.1, 'shift_amount': 0.00025}, # 10% ìº”ë“¤, 0.00025 ì´ë™
        ]
        
    def __len__(self):
        return int(np.ceil(self.samples / self.batch_size))
    
    def __getitem__(self, index):
        batch_indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]
        
        batch_images = []
        batch_labels = []
        
        for idx in batch_indexes:
            # ì´ë¯¸ì§€ ë¡œë“œ
            img_path = self.image_paths[idx]
            img = Image.open(img_path).convert('RGB')
            img = img.resize(self.img_size)
            img_array = np.array(img) / 255.0
            
            # ì¦ê°• ì ìš© (Training ì‹œì—ë§Œ)
            if self.augment and np.random.random() > 0.3:  # 70% í™•ë¥ ë¡œ ì¦ê°•
                aug_choice = np.random.choice(['candle_shift', 'gaussian_noise', 'both'])
                
                if aug_choice in ['candle_shift', 'both']:
                    # ìº”ë“¤ ì´ë™ ì¦ê°•
                    config = random.choice(self.aug_configs)
                    img_array = CandlestickAugmentation.shift_candles_vertically(
                        img_array, 
                        shift_ratio=config['shift_ratio'],
                        shift_amount=config['shift_amount']
                    )
                
                if aug_choice in ['gaussian_noise', 'both']:
                    # ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ ì¦ê°•
                    img_array = CandlestickAugmentation.add_gaussian_noise(
                        img_array, mean=0, var=0.01
                    )
            
            batch_images.append(img_array)
            batch_labels.append(self.labels[idx])
        
        return np.array(batch_images), np.array(batch_labels)
    
    def on_epoch_end(self):
        if self.shuffle:
            np.random.shuffle(self.indexes)


class CandlestickStockChartCNN:
    """ìº”ë“¤ìŠ¤í‹± ì°¨íŠ¸ ì „ìš© CNN ëª¨ë¸"""
    
    def __init__(self, data_dir, img_size=(128, 128), batch_size=32):
        self.data_dir = data_dir
        self.img_size = img_size
        self.batch_size = batch_size
        self.model = None
        self.base_model = None
        self.history_stage1 = None
        self.history_stage2 = None
        self.class_weights = None
        
    def explore_data(self):
        """ë°ì´í„°ì…‹ íƒìƒ‰"""
        print("="*60)
        print("ğŸ“Š ë°ì´í„°ì…‹ íƒìƒ‰")
        print("="*60)
        
        up_dir = os.path.join(self.data_dir, 'up')
        down_dir = os.path.join(self.data_dir, 'down')
        
        up_files = [f for f in os.listdir(up_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        down_files = [f for f in os.listdir(down_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        
        print(f"âœ… ìƒìŠ¹(Up) ì´ë¯¸ì§€: {len(up_files):,}ê°œ")
        print(f"âŒ í•˜ë½(Down) ì´ë¯¸ì§€: {len(down_files):,}ê°œ")
        print(f"ğŸ“ˆ ì´ ì´ë¯¸ì§€: {len(up_files) + len(down_files):,}ê°œ")
        
        # í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜
        total = len(up_files) + len(down_files)
        weight_down = total / (2 * len(down_files))
        weight_up = total / (2 * len(up_files))
        self.class_weights = {0: weight_down, 1: weight_up}
        
        print(f"âš–ï¸  í´ë˜ìŠ¤ ë¹„ìœ¨: Up={len(up_files)/total*100:.1f}%, Down={len(down_files)/total*100:.1f}%")
        print(f"ğŸ”§ í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜: Down={weight_down:.4f}, Up={weight_up:.4f}")
        print("="*60)
        
    def create_data_generators(self):
        """ìº”ë“¤ìŠ¤í‹± ì „ìš© ë°ì´í„° ì œë„ˆë ˆì´í„° ìƒì„±"""
        print("\nğŸ”„ ìº”ë“¤ìŠ¤í‹± ì „ìš© ë°ì´í„° ì œë„ˆë ˆì´í„° ìƒì„± ì¤‘...")
        print("ğŸ’¡ ë…¼ë¬¸ ê¸°ë°˜ ìº”ë“¤ìŠ¤í‹± ì°¨íŠ¸ ì¦ê°•:")
        print("   âœ… ìº”ë“¤ ë¬´ì‘ìœ„ ì´ë™ (100%, 50%, 10%)")
        print("   âœ… ì´ë™ í¬ê¸° (0.003, 0.002, 0.001, 0.00025)")
        print("   âœ… ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ (í‰ê·  0, ë¶„ì‚° 0.01)")
        print("   âŒ íšŒì „, ë°˜ì „, í¬ê¸° ì¡°ì ˆ ì œê±° (ì˜ë¯¸ ì—†ìŒ)")
        
        # Training generator (ì¦ê°• ì ìš©)
        self.train_generator = CandlestickDataGenerator(
            directory=self.data_dir,
            batch_size=self.batch_size,
            img_size=self.img_size,
            shuffle=True,
            augment=True,
            seed=42
        )
        
        # Validation generator (ì¦ê°• ë¯¸ì ìš©)
        self.val_generator = CandlestickDataGenerator(
            directory=self.data_dir,
            batch_size=self.batch_size,
            img_size=self.img_size,
            shuffle=False,
            augment=False,
            seed=42
        )
        
        # Train/Val ë¶„ë¦¬ (80/20)
        total_samples = self.train_generator.samples
        train_size = int(total_samples * 0.8)
        
        self.train_generator.indexes = self.train_generator.indexes[:train_size]
        self.train_generator.samples = train_size
        
        self.val_generator.indexes = self.val_generator.indexes[train_size:]
        self.val_generator.samples = total_samples - train_size
        
        print(f"âœ… Training ìƒ˜í”Œ: {self.train_generator.samples:,}ê°œ (ì¦ê°• ì ìš©)")
        print(f"âœ… Validation ìƒ˜í”Œ: {self.val_generator.samples:,}ê°œ (ì¦ê°• ë¯¸ì ìš©)")
        
    def build_model_stage1(self):
        """Stage 1: Transfer Learning ëª¨ë¸"""
        print("\nğŸ—ï¸  Stage 1: Transfer Learning ëª¨ë¸ êµ¬ì¶•...")
        
        base_model = ResNet50(
            include_top=False,
            weights='imagenet',
            input_shape=(self.img_size[0], self.img_size[1], 3),
            pooling='avg'
        )
        
        base_model.trainable = False
        
        inputs = keras.Input(shape=(self.img_size[0], self.img_size[1], 3))
        x = base_model(inputs, training=False)
        x = layers.BatchNormalization()(x)
        x = layers.Dropout(0.4)(x)
        x = layers.Dense(512, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001))(x)
        x = layers.BatchNormalization()(x)
        x = layers.Dropout(0.5)(x)
        x = layers.Dense(256, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001))(x)
        x = layers.BatchNormalization()(x)
        x = layers.Dropout(0.5)(x)
        outputs = layers.Dense(1, activation='sigmoid')(x)
        
        model = keras.Model(inputs, outputs)
        
        model.compile(
            optimizer=keras.optimizers.Adam(learning_rate=0.0001),
            loss='binary_crossentropy',
            metrics=['accuracy', keras.metrics.AUC(name='auc')]
        )
        
        self.model = model
        self.base_model = base_model
        
        print(f"âœ… Stage 1 ëª¨ë¸ êµ¬ì¶• ì™„ë£Œ")
        print(f"ğŸ“Š ì´ íŒŒë¼ë¯¸í„°: {model.count_params():,}ê°œ")
        
    def build_model_stage2(self, unfreeze_layers=60):
        """Stage 2: Fine-tuning"""
        print(f"\nğŸ”“ Stage 2: Fine-tuning (ë§ˆì§€ë§‰ {unfreeze_layers}ê°œ ë ˆì´ì–´ Unfreeze)...")
        
        self.base_model.trainable = True
        frozen_layers = len(self.base_model.layers) - unfreeze_layers
        
        for i, layer in enumerate(self.base_model.layers):
            layer.trainable = (i >= frozen_layers)
        
        self.model.compile(
            optimizer=keras.optimizers.Adam(learning_rate=0.00001),
            loss='binary_crossentropy',
            metrics=['accuracy', keras.metrics.AUC(name='auc')]
        )
        
        trainable_count = sum([tf.size(w).numpy() for w in self.model.trainable_weights])
        print(f"âœ… Fine-tuning ì¤€ë¹„ ì™„ë£Œ")
        print(f"ğŸ“Š Trainable íŒŒë¼ë¯¸í„°: {trainable_count:,}ê°œ")
        
    def train_stage(self, stage_name, epochs, save_path, patience=15):
        """ë‹¨ê³„ë³„ í•™ìŠµ"""
        print(f"\n{'='*60}")
        print(f"ğŸš€ {stage_name} í•™ìŠµ ì‹œì‘")
        print(f"{'='*60}")
        
        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        
        callbacks = [
            EarlyStopping(
                monitor='val_auc',
                patience=patience,
                restore_best_weights=True,
                mode='max',
                verbose=1
            ),
            ModelCheckpoint(
                save_path,
                monitor='val_auc',
                save_best_only=True,
                mode='max',
                verbose=1
            ),
            ReduceLROnPlateau(
                monitor='val_loss',
                factor=0.5,
                patience=8,
                min_lr=1e-8,
                verbose=1
            )
        ]
        
        print(f"â° ì‹œì‘: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        try:
            history = self.model.fit(
                self.train_generator,
                epochs=epochs,
                validation_data=self.val_generator,
                callbacks=callbacks,
                class_weight=self.class_weights,
                verbose=1
            )
            
            print(f"\nâœ… {stage_name} ì™„ë£Œ!")
            print(f"â° ì™„ë£Œ: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}")
            
            return history
            
        except KeyboardInterrupt:
            print(f"\nâš ï¸ {stage_name} ì¤‘ë‹¨ë¨")
            return None
            
    def evaluate(self):
        """ëª¨ë¸ í‰ê°€"""
        print("\n"+"="*60)
        print("ğŸ“Š ìµœì¢… ëª¨ë¸ í‰ê°€")
        print("="*60)
        
        # ì˜ˆì¸¡
        y_pred_proba_list = []
        y_true_list = []
        
        for i in range(len(self.val_generator)):
            x_batch, y_batch = self.val_generator[i]
            y_pred_batch = self.model.predict(x_batch, verbose=0)
            y_pred_proba_list.extend(y_pred_batch.flatten())
            y_true_list.extend(y_batch)
        
        y_pred_proba = np.array(y_pred_proba_list)
        y_true = np.array(y_true_list)
        y_pred = (y_pred_proba > 0.5).astype(int)
        
        # í‰ê°€ ì§€í‘œ
        accuracy = accuracy_score(y_true, y_pred)
        f1 = f1_score(y_true, y_pred)
        roc_auc = roc_auc_score(y_true, y_pred_proba)
        
        print(f"\nâœ… Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)")
        print(f"âœ… F1-Score: {f1:.4f}")
        print(f"âœ… ROC-AUC: {roc_auc:.4f}")
        
        print("\nğŸ“‹ Classification Report:")
        print(classification_report(y_true, y_pred, target_names=['Down (0)', 'Up (1)']))
        
        cm = confusion_matrix(y_true, y_pred)
        
        # íˆ¬ì ê´€ì 
        print("\nğŸ’° íˆ¬ì ê´€ì  í‰ê°€:")
        tn, fp, fn, tp = cm.ravel()
        hit_ratio_up = tp / (tp + fp) if (tp + fp) > 0 else 0
        hit_ratio_down = tn / (tn + fn) if (tn + fn) > 0 else 0
        
        print(f"   ğŸ“ˆ ìƒìŠ¹ ì˜ˆì¸¡ ì ì¤‘ë¥ : {hit_ratio_up:.2%}")
        print(f"   ğŸ“‰ í•˜ë½ ì˜ˆì¸¡ ì ì¤‘ë¥ : {hit_ratio_down:.2%}")
        
        return accuracy, f1, roc_auc, cm, y_true, y_pred_proba
        
    def plot_results(self, y_true, y_pred_proba):
        """ê²°ê³¼ ì‹œê°í™”"""
        print("\nğŸ“ˆ ê²°ê³¼ ì‹œê°í™” ì¤‘...")
        os.makedirs('results', exist_ok=True)
        
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        
        # 1. Accuracy
        if self.history_stage1 and self.history_stage2:
            epochs_s1 = len(self.history_stage1.history['accuracy'])
            epochs_s2 = len(self.history_stage2.history['accuracy'])
            
            all_train_acc = self.history_stage1.history['accuracy'] + self.history_stage2.history['accuracy']
            all_val_acc = self.history_stage1.history['val_accuracy'] + self.history_stage2.history['val_accuracy']
            
            axes[0, 0].plot(all_train_acc, label='Train', linewidth=2)
            axes[0, 0].plot(all_val_acc, label='Validation', linewidth=2)
            axes[0, 0].axvline(x=epochs_s1, color='red', linestyle='--', label='Fine-tuning ì‹œì‘')
            axes[0, 0].set_title('Accuracy (2-Stage)', fontweight='bold', fontsize=14)
            axes[0, 0].set_xlabel('Epoch')
            axes[0, 0].set_ylabel('Accuracy')
            axes[0, 0].legend()
            axes[0, 0].grid(alpha=0.3)
        
        # 2. AUC
        if self.history_stage1 and self.history_stage2:
            all_train_auc = self.history_stage1.history['auc'] + self.history_stage2.history['auc']
            all_val_auc = self.history_stage1.history['val_auc'] + self.history_stage2.history['val_auc']
            
            axes[0, 1].plot(all_train_auc, label='Train', linewidth=2)
            axes[0, 1].plot(all_val_auc, label='Validation', linewidth=2)
            axes[0, 1].axvline(x=epochs_s1, color='red', linestyle='--', label='Fine-tuning ì‹œì‘')
            axes[0, 1].set_title('ROC-AUC (2-Stage)', fontweight='bold', fontsize=14)
            axes[0, 1].set_xlabel('Epoch')
            axes[0, 1].set_ylabel('AUC')
            axes[0, 1].legend()
            axes[0, 1].grid(alpha=0.3)
        
        # 3. ROC Curve
        fpr, tpr, _ = roc_curve(y_true, y_pred_proba)
        roc_auc = roc_auc_score(y_true, y_pred_proba)
        
        axes[1, 0].plot(fpr, tpr, linewidth=3, label=f'ROC (AUC = {roc_auc:.4f})', color='blue')
        axes[1, 0].plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random')
        axes[1, 0].fill_between(fpr, tpr, alpha=0.2)
        axes[1, 0].set_title('ROC Curve', fontweight='bold', fontsize=14)
        axes[1, 0].set_xlabel('False Positive Rate')
        axes[1, 0].set_ylabel('True Positive Rate')
        axes[1, 0].legend()
        axes[1, 0].grid(alpha=0.3)
        
        # 4. Confusion Matrix
        cm = confusion_matrix(y_true, (y_pred_proba > 0.5).astype(int))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[1, 1],
                   xticklabels=['Down', 'Up'], yticklabels=['Down', 'Up'])
        axes[1, 1].set_title('Confusion Matrix', fontweight='bold', fontsize=14)
        axes[1, 1].set_ylabel('True Label')
        axes[1, 1].set_xlabel('Predicted Label')
        
        plt.tight_layout()
        plt.savefig('results/candlestick_aug_results.png', dpi=300, bbox_inches='tight')
        print("âœ… ì €ì¥: results/candlestick_aug_results.png")
        plt.close()


def create_subset_if_needed(source_dir, target_dir, num_samples_per_class=2500):
    """ì„œë¸Œì…‹ ë°ì´í„°ì…‹ ìƒì„± (í•„ìš”ì‹œ)"""
    if os.path.exists(target_dir):
        print(f"\nâœ… ì„œë¸Œì…‹ ë°ì´í„°ì…‹ ì¡´ì¬: {target_dir}")
        return target_dir
    
    print("\n"+"="*60)
    print("ğŸ“¦ 5,000ì¥ ì„œë¸Œì…‹ ìƒì„± ì¤‘...")
    print("="*60)
    
    os.makedirs(target_dir, exist_ok=True)
    random.seed(42)
    
    for class_name in ['up', 'down']:
        print(f"\nğŸ“‚ í´ë˜ìŠ¤: {class_name}")
        
        source_class_dir = os.path.join(source_dir, class_name)
        target_class_dir = os.path.join(target_dir, class_name)
        os.makedirs(target_class_dir, exist_ok=True)
        
        all_files = [f for f in os.listdir(source_class_dir) 
                     if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        
        print(f"   ğŸ“Š ì „ì²´: {len(all_files):,}ê°œ")
        
        sampled_files = random.sample(all_files, min(num_samples_per_class, len(all_files)))
        print(f"   ğŸ¯ ìƒ˜í”Œë§: {len(sampled_files):,}ê°œ")
        
        for i, filename in enumerate(sampled_files, 1):
            shutil.copy2(
                os.path.join(source_class_dir, filename),
                os.path.join(target_class_dir, filename)
            )
            if i % 500 == 0:
                print(f"   â³ ë³µì‚¬ ì¤‘: {i}/{len(sampled_files)}")
        
        print(f"   âœ… ì™„ë£Œ: {len(sampled_files):,}ê°œ")
    
    print("\n"+"="*60)
    print("âœ… ì„œë¸Œì…‹ ìƒì„± ì™„ë£Œ!")
    print("="*60)
    
    return target_dir


def main():
    """ë©”ì¸ ì‹¤í–‰"""
    print("\n"+"="*60)
    print("ğŸš€ ìº”ë“¤ìŠ¤í‹± ì°¨íŠ¸ ì „ìš© ë°ì´í„° ì¦ê°• ëª¨ë¸")
    print("ğŸ’¡ ë…¼ë¬¸ ê¸°ë°˜ ì¦ê°• + ResNet50 Transfer Learning")
    print("="*60)
    
    # GPU ì„¤ì •
    gpus = tf.config.experimental.list_physical_devices('GPU')
    batch_size = 128 if gpus else 64
    
    print(f"\nğŸ“Š ì„¤ì •:")
    print(f"   - ë°°ì¹˜ í¬ê¸°: {batch_size} (GPU: {'ì‚¬ìš©' if gpus else 'ë¯¸ì‚¬ìš©'})")
    print(f"   - ì´ë¯¸ì§€ í¬ê¸°: 128Ã—128")
    print(f"   - ë°ì´í„°ì…‹: 5,000ì¥")
    
    # ì„œë¸Œì…‹ ìƒì„±
    data_dir = create_subset_if_needed(
        source_dir='dataset-2021',
        target_dir='dataset-subset-5k',
        num_samples_per_class=2500
    )
    
    # ëª¨ë¸ ì´ˆê¸°í™”
    model = CandlestickStockChartCNN(
        data_dir=data_dir,
        img_size=(128, 128),
        batch_size=batch_size
    )
    
    # ë°ì´í„° íƒìƒ‰
    model.explore_data()
    
    # ë°ì´í„° ì œë„ˆë ˆì´í„° ìƒì„±
    model.create_data_generators()
    
    # Stage 1: Transfer Learning
    print("\n"+"#"*60)
    print("ğŸ“Œ STAGE 1: Transfer Learning")
    print("#"*60)
    
    model.build_model_stage1()
    model.history_stage1 = model.train_stage(
        stage_name="Stage 1 - Transfer Learning",
        epochs=50,
        save_path='models/candlestick_aug/stage1_best.keras',
        patience=15
    )
    
    # Stage 2: Fine-tuning
    print("\n"+"#"*60)
    print("ğŸ“Œ STAGE 2: Fine-tuning")
    print("#"*60)
    
    model.build_model_stage2(unfreeze_layers=60)
    model.history_stage2 = model.train_stage(
        stage_name="Stage 2 - Fine-tuning",
        epochs=50,
        save_path='models/candlestick_aug/stage2_best.keras',
        patience=15
    )
    
    # ìµœì¢… í‰ê°€
    accuracy, f1, roc_auc, cm, y_true, y_pred_proba = model.evaluate()
    
    # ê²°ê³¼ ì‹œê°í™”
    model.plot_results(y_true, y_pred_proba)
    
    # ìµœì¢… ìš”ì•½
    print("\n"+"="*60)
    print("ğŸ‰ ìº”ë“¤ìŠ¤í‹± ì¦ê°• ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")
    print("="*60)
    print(f"ğŸ“Š ìµœì¢… Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)")
    print(f"ğŸ“Š F1-Score: {f1:.4f}")
    print(f"ğŸ“Š ROC-AUC: {roc_auc:.4f}")
    print("="*60)
    
    # ë¹„êµ
    print("\n"+"="*60)
    print("ğŸ“Š ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ")
    print("="*60)
    print("ê¸°ì¡´ ëª¨ë¸:")
    print("   - Accuracy: 54.96% (ë‹¨ìˆœ CNN)")
    print("   - Accuracy: 53.30% (ResNet50, ì¼ë°˜ ì¦ê°•)")
    print("\nìº”ë“¤ìŠ¤í‹± íŠ¹í™” ì¦ê°•:")
    print(f"   - Accuracy: {accuracy*100:.2f}%")
    print(f"   - F1-Score: {f1:.4f}")
    print(f"   - ROC-AUC: {roc_auc:.4f}")
    print("   - ë…¼ë¬¸ ê¸°ë°˜ ìº”ë“¤ìŠ¤í‹± ì¦ê°• ì ìš©")
    print("   - 2ë‹¨ê³„ Fine-tuning ì™„ë£Œ")
    print("="*60)


if __name__ == '__main__':
    main()

